{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Task3\n",
        "##Anshika PH20C005"
      ],
      "metadata": {
        "id": "dfHamqEAdHHT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Imports"
      ],
      "metadata": {
        "id": "AaNdJDFGjEA-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vZpBxSYMmzrG"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "!wget https://storage.googleapis.com/wandb_datasets/nature_12K.zip\n",
        "!unzip /content/nature_12K.zip\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "DvB6NNxsnJyi"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchsummary import summary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oQ_qcF9nxWy"
      },
      "source": [
        "# Dataloader\n",
        "\n",
        "- Dataset Class for Setting up the data loading process\n",
        "- Sections to fill in this script: `_init_transform()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "0xJnjBM-ntqN"
      },
      "outputs": [],
      "source": [
        "class inaturalist(Dataset):\n",
        "    def __init__(self, root_dir, mode , transform = True):\n",
        "        self.data_dir = root_dir\n",
        "        self.mode = mode\n",
        "        self.transforms = transform      \n",
        "        self._init_dataset()\n",
        "        if transform:\n",
        "            self._init_transform()\n",
        "\n",
        "    def _init_dataset(self):\n",
        "        self.files = []\n",
        "        self.labels = []\n",
        "        dirs = sorted(os.listdir(os.path.join(self.data_dir, 'train')))\n",
        "        if self.mode == 'train': \n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'train', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        elif self.mode == 'val':\n",
        "            for dir in range(len(dirs)):\n",
        "                files = sorted(glob(os.path.join(self.data_dir, 'val', dirs[dir], '*.jpg')))\n",
        "                self.labels += [dir]*len(files)            \n",
        "                self.files += files\n",
        "        else:\n",
        "            print(\"No Such Dataset Mode\")\n",
        "            return None\n",
        "        \n",
        "    def _init_transform(self):\n",
        "        self.transform = transforms.Compose([transforms.Resize((227,227)), transforms.ToTensor(), transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "        ])\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        img = Image.open(self.files[index]).convert('RGB')\n",
        "        label = self.labels[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = torch.tensor(label, dtype = torch.long)\n",
        "\n",
        "        return img, label\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJccgV5Knzi6"
      },
      "source": [
        "# Model\n",
        "\n",
        "- Class to define the model which we will use for training\n",
        "- Stuff to fill in: The Architecture of your model, the `forward` function to define the forward pass\n",
        "\n",
        "NOTE!: You are NOT allowed to use pretrained models for this task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1AYXvAZFqkzT"
      },
      "outputs": [],
      "source": [
        "\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.l1 = nn.Sequential(\n",
        "            nn.Conv2d(3, 96, kernel_size=11, stride=4, padding=0),\n",
        "            nn.BatchNorm2d(96),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.l2 = nn.Sequential(\n",
        "            nn.Conv2d(96, 256, kernel_size=5, stride=1, padding=2),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.l3 = nn.Sequential(\n",
        "            nn.Conv2d(256, 384, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(384),\n",
        "            nn.ReLU())\n",
        "        self.l4 = nn.Sequential(\n",
        "            nn.Conv2d(384, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(kernel_size = 3, stride = 2))\n",
        "        self.fc1 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(9216, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc2 = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU())\n",
        "        self.fc3= nn.Sequential(\n",
        "            nn.Linear(4096, num_classes))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.l1(x)\n",
        "        out = self.l2(out)\n",
        "        out = self.l3(out)\n",
        "        out = self.l4(out)\n",
        "        out = out.reshape(out.size(0), -1)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i3bFLsdoF1_"
      },
      "source": [
        "# Training\n",
        "\n",
        "- Sections to Fill: Define `loss` function, `optimizer` and model, `train` and `eval` functions and the training loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CSnVvW2XoUtS"
      },
      "source": [
        "## Hyperparameters\n",
        "\n",
        "Feel free to change these hyperparams based on your machine's capactiy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "VOZBwxHUn1jl"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 5\n",
        "learning_rate = 0.01\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZqeVDE4oZ0H"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Dmsg0xP8oYTR"
      },
      "outputs": [],
      "source": [
        "trainset = inaturalist(root_dir='/content/inaturalist_12K', mode='train',transform = True)\n",
        "valset = inaturalist(root_dir='/content/inaturalist_12K', mode = 'val',transform = True)\n",
        "\n",
        "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "valloader = DataLoader(valset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBhjYABpobqY"
      },
      "source": [
        "## Loss Function and Optimizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "c8LY3Yiloe4M"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "model= Classifier().to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M9bEWwU-ohzG"
      },
      "source": [
        "## Checkpoints\n",
        "\n",
        "To save your model weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "6t5vtHaLofac"
      },
      "outputs": [],
      "source": [
        "checkpoint_dir = 'checkpoints'\n",
        "if not os.path.isdir(checkpoint_dir):\n",
        "    os.makedirs(checkpoint_dir)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VTLTwpfmopqu"
      },
      "source": [
        "## Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "cM9OFbjjojax"
      },
      "outputs": [],
      "source": [
        "def get_model_summary(model, input_tensor_shape):\n",
        "    summary(model, input_tensor_shape)\n",
        "\n",
        "def accuracy(y_pred, y):\n",
        "    _, predicted = torch.max(y_pred.data, 1)\n",
        "    total = y.size(0)\n",
        "    correct = (predicted == y).sum().item()\n",
        "    return correct/total\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCr-_BHxosFO"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "MaSzNltYorsv"
      },
      "outputs": [],
      "source": [
        "def train(model, trainloader, optimizer, criterion, device):\n",
        "    '''\n",
        "    Function to train the model for one epoch\n",
        "    '''\n",
        "    for image, label in trainloader:\n",
        "      image = image.to(device)\n",
        "      label = label.to(device)\n",
        "      label=label-1\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      output = model(image)\n",
        "\n",
        "      loss = criterion(output, label)\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OadZ2Iwmouui"
      },
      "source": [
        "## Eval"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "8NKlJQpIouM5"
      },
      "outputs": [],
      "source": [
        "def eval(model, dataset, criterion, device):\n",
        "\n",
        "    '''\n",
        "    Function to validate the model after each epoch\n",
        "    '''\n",
        "\n",
        "    with torch.no_grad():\n",
        "      correct=0\n",
        "      total=0\n",
        "      for image, label in dataset:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "        label=label-1\n",
        "        output= model(image)\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (predicted == label).sum().item()\n",
        "        del image,label,output\n",
        "    print(\"Accuracy is \", (correct/total)* 100)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1AIrmEeozK4"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfFkPREqov9j",
        "outputId": "f44c3e44-1307-4450-8555-266e023bda24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy is  9.950000000000001\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 23 mins and 45 seconds\n",
            "Accuracy is  10.0\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 23 mins and 35 seconds\n",
            "Accuracy is  9.950000000000001\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 27 mins and 49 seconds\n",
            "Accuracy is  10.0\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 27 mins and 22 seconds\n",
            "Accuracy is  10.0\n",
            "\n",
            "\n",
            "\n",
            " TIME TAKEN FOR THE EPOCH: 27 mins and 34 seconds\n",
            "OVERALL TRAINING COMPLETE\n"
          ]
        }
      ],
      "source": [
        "best_valid_loss = float('inf')\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    \n",
        "    start_time = time.monotonic()\n",
        "    \n",
        "    train(model,trainloader, optimizer,criterion, device)\n",
        "\n",
        "    eval(model, valloader,criterion, device)\n",
        "\n",
        "\n",
        "    end_time = time.monotonic()\n",
        "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "\n",
        "    print(\"\\n\\n\\n TIME TAKEN FOR THE EPOCH: {} mins and {} seconds\".format(epoch_mins, epoch_secs))\n",
        "\n",
        "\n",
        "print(\"OVERALL TRAINING COMPLETE\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Image-Classification- CNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}